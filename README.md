# ğŸ§  Minesweeper Reinforcement Learning Project

This project trains and evaluates reinforcement learning agents to play Minesweeper.
This project includes a Minesweeper environment (Gymnasium-style) and a Deep Q-Network (DQN) agent with a CNN backbone.
The original project environment can be found here: https://github.com/markov-labs/RL-Minesweeper


## ğŸ“ Project Structure

```
minesweeper-rl/
â”œâ”€â”€ backend/                 # Core game logic, board generation, game state
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ board.py             # MinesweeperBoard class: logic, reveal, flag, etc.
â”‚   â”œâ”€â”€ game.py              # GameSession class: player actions, win/loss, resets
â”‚   â””â”€â”€ utils.py             # Helper functions (e.g., random board gen, display)

â”œâ”€â”€ frontend/                # Local web interface (Flask + JS or full SPA)
â”‚   â”œâ”€â”€ static/              # JS, CSS, images
â”‚   â”œâ”€â”€ templates/           # HTML templates
â”‚   â”œâ”€â”€ app.py               # Flask app (serves game + API for model interaction)
â”‚   â””â”€â”€ api.py               # Defines REST endpoints (e.g., /new_game, /step, /state)

â”œâ”€â”€ models/                             # Folder for RL agents
â”‚   â”œâ”€â”€ base_agent.py                   # BaseAgent class (standard API: act(), observe(), train())
â”‚   â”œâ”€â”€ dqn_agent/                      # DQN + CNN Agent
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py                # DQNAgent(BaseAgent)
â”‚   â”‚   â””â”€â”€ config.yaml                 # Custom Configuration
â”‚   â””â”€â”€ registry.py                     # Auto-discovery / loading of available models

â”œâ”€â”€ evaluation/              # Code for running and comparing models
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ leaderboard.json     # Optional: shared results
â”‚   â””â”€â”€ visualizer.py        # For replay rendering, statistics, heatmaps

â”œâ”€â”€ notebooks/               # Optional: for experimentation, debugging, analysis

â”œâ”€â”€ config/                  # Game or training configs (YAML or JSON)
â”‚   â”œâ”€â”€ game_config.yaml
â”‚   â””â”€â”€ training_config.yaml

â”œâ”€â”€ tests/                   # Unit tests for backend, models
â”‚   â””â”€â”€ test_board.py

â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.py                 # Optional: make it pip-installable as a package
```

## Installation

```bash
python -m venv .venv
# Windows: 
source venv/scripts/activate
# macOS/Linux
source .venv/bin/activate

pip install -r requirements.txt

```

## Quick Start
To train the DQNAgent, you can run:

```bash
python -m models.dqn_agent.dqn_agent --episodes 100
```

Similarly, to train the DQN_CNN_Agent, you can run:
```bash
python -m models.dqn_cnn_agent.dqn_cnn_agent --episodes 100
```

Common outputs:
- A saved model checkpoint (.pth)
- A CSV of training states (loss, reward, epsilon, steps)

## Evaluate a Saved Model
To evaluate a saved model, you can run:
```bash
python -m evaluation.evaluate

```
